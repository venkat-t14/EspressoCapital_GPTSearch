{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from fastapi.encoders import jsonable_encoder\n",
    "import requests\n",
    "from utils import parse_stream_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function(s) for Calling LLM Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_result(\n",
    "    prompt, api_key_header, stream=False\n",
    "):\n",
    "    url = \"https://api.obviously.ai/v3/llm/inference\"\n",
    "    headers = {\n",
    "        \"Authorization\": api_key_header,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        \"additional_params\": {\"temperature\": 0.7, \"max_tokens\": 256, \"stream\": stream},\n",
    "    }\n",
    "    response = requests.post(url, stream=stream, json=payload, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        \n",
    "        if stream:\n",
    "            parse_stream_output(response) # Print out API response as a stream\n",
    "            return False, 200\n",
    "            \n",
    "        else:\n",
    "            print(response.text) # Print out API response as a JSON string\n",
    "            return False, 200\n",
    "    else:\n",
    "        print(response.text) # Print out API Error response as a JSON string\n",
    "        return True, response.status_code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POST Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST /search/:search_id\n",
    "\n",
    "req = json.loads(REQUEST)\n",
    "body = req[\"body\"]  # Request Body Dict\n",
    "query_params = req.get(\"args\", {}) # Query Param Dict\n",
    "path_params = req.get(\"path\", {}) # Path Param Dict\n",
    "headers = req[\"headers\"] # Request Header dict\n",
    "stream = True if query_params.get(\"stream\") else False\n",
    "\n",
    "search_id = path_params.get(\"search_id\")\n",
    "\n",
    "error = False  # Set this to 'True' if you encounter error. Print out any error message post-json-serialization\n",
    "error_code = 400\n",
    "\n",
    "api_key_header = headers.get(\"Authorization\")\n",
    "\n",
    "if not api_key_header:\n",
    "    error = True\n",
    "    error_code = 401\n",
    "    error_response = {\"detail\": \"Unauthorized\"}\n",
    "    print(json.dumps(error_response))  # Print out API Error response as a JSON string\n",
    "\n",
    "else:\n",
    "    ########\n",
    "    ### Call any Pre-processing functions/code below: ###\n",
    "    ########\n",
    "    prompt = body.get(\"prompt\")\n",
    "\n",
    "    # Call obv.ai LLM endpoint with your prompt below:\n",
    "\n",
    "    error, error_code = generate_result(\n",
    "        prompt,\n",
    "        api_key_header,\n",
    "        stream=stream,\n",
    "    )\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response codes defined below for endpoint `/search/:search_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResponseInfo POST /search/:search_id\n",
    "\n",
    "if error:\n",
    "    print(json.dumps({\n",
    "        \"headers\": {\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        },\n",
    "        \"status\": error_code\n",
    "    }))\n",
    "elif stream:\n",
    "    print(\n",
    "        json.dumps(\n",
    "            {\n",
    "                \"headers\": {\n",
    "                    \"Content-Type\": \"text/event-stream\",\n",
    "                    \"x-accel-buffering\": \"no\"\n",
    "                },\n",
    "                \"status\": 200,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(json.dumps({\n",
    "        \"headers\": {\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        },\n",
    "        \"status\": 200\n",
    "    }))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the `notebooks` directory, run the notebook using command:\n",
    "\n",
    "```\n",
    "jupyter kernelgateway --api='kernel_gateway.notebook_http' --seed_uri='main.ipynb' --port 9090\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
